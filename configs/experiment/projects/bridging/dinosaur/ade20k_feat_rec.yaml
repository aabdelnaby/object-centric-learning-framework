# @package _global_
# ViT feature reconstruction on ADE20K using DINOSAUR hierarchy.
defaults:
  - /experiment/projects/bridging/dinosaur/_base_feature_recon
  - /dataset: ade20k_dino
  - _self_

trainer:
  devices: 4
  max_steps: 500000

dataset:
  batch_size: 8
  num_workers: 8

# Disable metrics that expect MOVI-style instance masks.
training_metrics: {}
evaluation_metrics: {}

experiment:
  input_feature_dim: 384
  hierarchy:
    depth: 3
    child_per_parent: 2
    child_loss_weight: 0.3
    child2_loss_weight: 0.2

models:
  conditioning:
    _target_: routed.ocl.conditioning.RandomConditioning
    n_slots: 4
    object_dim: 128
    batch_size_path: input.batch_size
  feature_extractor:
    _target_: routed.ocl.feature_extractors.TimmFeatureExtractor
    model_name: vit_small_patch8_224_dino
    pretrained: true
    freeze: true
    feature_level: 12

  perceptual_grouping:
    positional_embedding:
      _target_: ocl.neural_networks.wrappers.Sequential
      _args_:
        - _target_: ocl.neural_networks.positional_embedding.DummyPositionEmbed
        - _target_: ocl.neural_networks.build_two_layer_mlp
          input_dim: 384
          output_dim: ${....feature_dim}
          hidden_dim: 384
          initial_layer_norm: true

  object_decoder:
    _target_: routed.ocl.decoding.PatchDecoder
    object_dim: ${models.perceptual_grouping.object_dim}
    output_dim: ${experiment.input_feature_dim}
    num_patches: 784
    decoder:
      _target_: ocl.neural_networks.build_mlp
      _partial_: true
      features: [1024, 1024, 1024]
    object_features_path: perceptual_grouping.objects

  hierarchical_refine:
    _target_: routed.ocl.hierarchy.HierarchicalSlots
    tokens_path: feature_extractor.features
    parent_slots_path: perceptual_grouping.objects
    parent_masks_path: object_decoder.masks
    child_per_parent: ${experiment.hierarchy.child_per_parent}
    slot_dim: ${models.conditioning.object_dim}
    sa_iters: 3
    feature_dim: null
    use_sa_attention_for_gating: true
    use_straight_through_gumbel: true
    gumbel_temperature: 1.0

  object_decoder_child:
    _target_: routed.ocl.decoding.PatchDecoder
    object_dim: ${models.perceptual_grouping.object_dim}
    output_dim: ${experiment.input_feature_dim}
    num_patches: 784
    decoder:
      _target_: ocl.neural_networks.build_mlp
      _partial_: true
      features: [1024, 1024, 1024]
    object_features_path: hierarchical_refine.child_objects
    gating_mask_path: hierarchical_refine.child_gating_masks
    image_path: input.image

  hierarchical_refine_l2:
    _target_: routed.ocl.hierarchy.HierarchicalSlots
    tokens_path: feature_extractor.features
    parent_slots_path: hierarchical_refine.child_objects
    parent_masks_path: object_decoder_child.masks
    child_per_parent: ${experiment.hierarchy.child_per_parent}
    slot_dim: ${models.conditioning.object_dim}
    sa_iters: 3
    feature_dim: null
    use_sa_attention_for_gating: true
    use_straight_through_gumbel: true
    gumbel_temperature: 1.0

  object_decoder_grandchild:
    _target_: routed.ocl.decoding.PatchDecoder
    object_dim: ${models.perceptual_grouping.object_dim}
    output_dim: ${experiment.input_feature_dim}
    num_patches: 784
    decoder:
      _target_: ocl.neural_networks.build_mlp
      _partial_: true
      features: [1024, 1024, 1024]
    object_features_path: hierarchical_refine_l2.child_objects
    gating_mask_path: hierarchical_refine_l2.child_gating_masks
    image_path: input.image

  masks_as_image:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: object_decoder.masks
    size: 128
    resize_mode: bilinear
    patch_mode: true

  child_masks_as_image:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: object_decoder_child.masks
    size: 128
    resize_mode: bilinear
    patch_mode: true

  grandchild_masks_as_image:
    _target_: routed.ocl.utils.resizing.Resize
    input_path: object_decoder_grandchild.masks
    size: 128
    resize_mode: bilinear
    patch_mode: true

visualizations:
  child_masks:
    _target_: routed.ocl.visualizations.Mask
    mask_path: child_masks_as_image
  grandchild_masks:
    _target_: routed.ocl.visualizations.Mask
    mask_path: grandchild_masks_as_image

losses:
  mse_child:
    _target_: routed.ocl.losses.ReconstructionLoss
    loss_type: mse
    weight: "${eval_lambda:'lambda d, w: 0.0 if d < 2 else w', ${experiment.hierarchy.depth}, ${experiment.hierarchy.child_loss_weight}}"
    input_path: object_decoder_child.reconstruction
    target_path: object_decoder.target
  mse_child2:
    _target_: routed.ocl.losses.ReconstructionLoss
    loss_type: mse
    weight: "${eval_lambda:'lambda d, w: 0.0 if d < 3 else w', ${experiment.hierarchy.depth}, ${experiment.hierarchy.child2_loss_weight}}"
    input_path: object_decoder_grandchild.reconstruction
    target_path: object_decoder.target
